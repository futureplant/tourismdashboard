{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Notebook for retrieving and processing Flickr data from the API (http://insideairbnb.com/)</b>\n",
    "* All rights reserved to the respective owners.\n",
    "* The author of this script is not affiliated with Flickr or any of Flickr's competitors.\n",
    "* Sensitive information, namely 'username', is removed in the final CSV file to ensure anonymity of Flickr users  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import flickrapi\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "api_key = 'insert your own api key'\n",
    "api_secret = 'insert your own secret key'\n",
    "flickr = flickrapi.FlickrAPI(api_key, api_secret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Retrieving Flickr data </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new folder in output\n",
    "out_folder = './output/flickr_data'\n",
    "if os.path.exists(out_folder):\n",
    "    shutil.rmtree(out_folder)\n",
    "os.makedirs(out_folder)\n",
    "\n",
    "#retrieve Flickr data form the API and write into csv\n",
    "with open('./output/flickr_data/sample_flickr_24june2019.csv', 'w') as csvFile:\n",
    "    \n",
    "    #specify attributes to retrieve and open empty csv file\n",
    "    fieldnames = ['photo_id','photo_title','username','date_posted','date_taken','user_location','lat','lon']\n",
    "    writer = csv.DictWriter(csvFile, fieldnames=fieldnames,lineterminator = '\\n')\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # access the API and retrieve every photos based on #amsterdam and bbox\n",
    "    #also write values into csv file\n",
    "    for photo in flickr.walk(per_page=500,tag_mode='any',tags='amsterdam',extras=\"geo\",\n",
    "                             bbox=\"4.702148,52.282442,5.059891,52.459775\"):\n",
    "        try:\n",
    "            photo_title = photo.attrib['title']\n",
    "            photo_id = photo.attrib['id']\n",
    "            lat = photo.attrib['latitude']\n",
    "            lon =  photo.attrib['longitude']\n",
    "            \n",
    "            bulk_info_byte = flickr.photos.getInfo(photo_id=photo_id,format='json')\n",
    "            json = bulk_info_byte.decode('utf8')\n",
    "            username = (json[json.find('\"username\":\"')+len('\"username\":\"'):json.rfind('\",\"realname\"')])\n",
    "            date_posted = json[json.find('\"dates\":{\"posted\":\"')+len('\"dates\":{\"posted\":\"'):json.rfind('\",\"taken\"')]\n",
    "            date_posted = datetime.datetime.fromtimestamp(int(date_posted))\n",
    "            date_taken = json[json.find('\"taken\":\"')+len('\"taken\":\"'):json.rfind('\",\"takengranularity\"')]\n",
    "            date_taken = datetime.datetime.strptime(date_taken, '%Y-%m-%d %H:%M:%S')\n",
    "            user_location = json[json.find('\"location\":\"')+len('\"location\":\"'):json.rfind('\",\"iconserver\"')]\n",
    "            \n",
    "            writer.writerow({'photo_id': photo_id,'photo_title': photo_title,'username':username,'date_posted':date_posted,\n",
    "                             'date_taken':date_taken,'user_location':user_location,'lat': lat,'lon':lon})\n",
    "            time.sleep(1)\n",
    "            print(username)\n",
    "        except (FlickrError,NameError,UnicodeEncodeError) as e:\n",
    "            time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Cleaning data </B> <br>\n",
    "CSV contains data that was retrieved 24june2019 (3000+ photos). Data cleaning script may not be approriate for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data \n",
    "df = pd.read_csv('./output/flickr_data/sample_flickr_24june2019.csv',encoding = \"ISO-8859-1\")\n",
    "df['date_taken'] = pd.to_datetime(df['date_taken'])\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])\n",
    "df['country'] = df[\"user_location\"]\n",
    "df['country'] = df[\"user_location\"].str.split(\",\", n = 1, expand = True)[[1]]\n",
    "df['country'] = df['country'].str.strip()\n",
    "df.fillna(value='-',inplace=True)\n",
    "df[\"traveler_type\"] = \"\"\n",
    "df['country']= np.where(df['country']=='-', df['user_location'], df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label based on country\n",
    "nl = ['Nederland','Netherlands','The Netherlands','Holland','NL','the Netherlands','nederland']\n",
    "df.loc[df['country'].isin(nl),'traveler_type'] = 'domestic'\n",
    "df.loc[df['user_location'].str.contains('Amsterdam'),'traveler_type'] = 'local'\n",
    "df.loc[df['user_location'].str.contains('Utrecht') | df['user_location'].str.contains('Amersfoort'),'traveler_type'] = 'domestic'\n",
    "\n",
    "df.loc[df['user_location'].str.contains('Amsterdam'),'traveler_type'] = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset = df.loc[df['user_location']=='-'].groupby(['username','date_taken']).size().reset_index()\n",
    "subset['month_nr'] = subset['date_taken'].apply(lambda x: \"%d\" % (x.month))\n",
    "subset = subset.groupby(['username', 'month_nr']).size().reset_index(name='photo_frequency')\n",
    "\n",
    "# label based on amount of photos per month\n",
    "# international more than 100 photos, domestic between 10-100, local less than 10\n",
    "subset.loc[subset['photo_frequency']>100,'traveler_type'] = 'international'\n",
    "subset.loc[(subset['photo_frequency']>=10) & (subset['photo_frequency']<=100),'traveler_type']= 'domestic'\n",
    "subset.loc[subset['photo_frequency']<10,'traveler_type'] = 'local'\n",
    "subset = subset.groupby(['username','traveler_type']).size().reset_index(name='count')\n",
    "subset.drop(columns='count',inplace=True)\n",
    "df = df.merge(subset,on='username',how = 'outer')\n",
    "df['traveler_type_x']= np.where(df['traveler_type_x']=='', df['traveler_type_y'], df['traveler_type_x'])\n",
    "df.drop(columns='traveler_type_y',inplace=True)\n",
    "df.rename(columns={'traveler_type_x': 'traveler_type'}, inplace=True)\n",
    "\n",
    "df.loc[df['traveler_type'].isnull(),'traveler_type']='international'\n",
    "\n",
    "df = df.drop_duplicates(subset='photo_id', keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete username\n",
    "df.drop(['username'], axis=1,inplace=True)\n",
    "\n",
    "#export dataframe to geojson\n",
    "df['date_posted'] = df['date_posted'].dt.strftime('%Y-%m-%d')\n",
    "df['date_taken'] = df['date_taken'].dt.strftime('%Y-%m-%d')\n",
    "geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "flickr_gdf = df.drop(['lat', 'lon'], axis=1)\n",
    "flickr_gdf = GeoDataFrame(flickr_gdf, crs={'init': 'epsg:4326'}, geometry=geometry)\n",
    "flickr_gdf.to_file(\"./output/flickr_data/GeotaggedFlickr_24june2019.geojson\",driver=\"GeoJSON\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete csv file\n",
    "filePath = './output/flickr_data/sample_flickr_24june2019.csv'; \n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath)\n",
    "else:\n",
    "    print(\"Can not delete the file as it doesn't exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
