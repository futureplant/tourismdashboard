{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Notebook for retrieving and processing Twitter data using the API</b>\n",
    "* All rights reserved to the respective owners.\n",
    "* The author of this script is not affiliated with Twitter or any of Twitter's competitors.\n",
    "* No private information is being used. The final data product contain mainly locatin informaiton and ids\n",
    "* Script that deals with the twitter data as described in paragraph 3.3.1 of the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "from twython import TwythonStreamer\n",
    "import string, json, pprint\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from time import *\n",
    "import string, os, sys, subprocess, time\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new folder in output\n",
    "out_folder = './output/twitter_data'\n",
    "if os.path.exists(out_folder):\n",
    "    shutil.rmtree(out_folder)\n",
    "os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access to your Twitter API\n",
    "APP_KEY = \"YOUR APP KEY\"\n",
    "APP_SECRET = \"YOUR SECRET KEY\"\n",
    "OAUTH_TOKEN = \"YOUR TOKEN\"\n",
    "OAUTH_TOKEN_SECRET = \"YOUR SECRET TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just some date and time to generate an unique filename if needed\n",
    "#change file name if needed\n",
    "output_file = './output/twitter_data/GeotaggedTweets_22to23june2019+ '.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to process JSON data comming from the twitter stream API. Extract relevant fields\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    #This function will calles when data has been seccessfully received from stream an define the attributes will be retrieved from Twitter API\n",
    "    def on_success(self, data):\n",
    "        tweet_lat = 0.0\n",
    "        tweet_lon = 0.0\n",
    "        tweet_name = \"\"\n",
    "        retweet_count = 0 \n",
    "\n",
    "        if 'id' in data:\n",
    "            tweet_id = data['id']\n",
    "        if 'coordinates' in data:    \n",
    "               geo = data['coordinates']\n",
    "                if not geo is None:\n",
    "                    latlon = geo['coordinates']\n",
    "                    tweet_lon = latlon[0]\n",
    "                    tweet_lat= latlon[1]\n",
    "        if 'created_at' in data:\n",
    "            dt = data['created_at']\n",
    "            tweet_datetime = datetime.strptime(dt, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "        if tweet_lat != 0:\n",
    "            #some elementary output to console    \n",
    "            string_to_write = str(tweet_datetime)+\", \"+str(tweet_lat)+\", \"+str(tweet_lon)+\": \"+str(tweet_text)\n",
    "            print(string_to_write)\n",
    "            #write_tweet(string_to_write)\n",
    "                    \n",
    "    #Basic function to write tweets to a file\n",
    "    def write_tweet(tweet, output_file):\n",
    "        target = open(output_file, 'a')\n",
    "        target.write(tweet)\n",
    "        target.write('\\n')\n",
    "        target.close() \n",
    "    #This function will called when stream returns non-200 status code     \n",
    "    def on_error(self, status_code, data):\n",
    "         print(\"OOPS Error: \" +str(status_code))\n",
    "         #self.disconnect\n",
    "         \n",
    "         #Main procedure where the MyStreamer class is instantiated (with all authentication tokens)\n",
    "         #and next only capture those tweets within a certain bounding box\n",
    "def main():\n",
    "    try:\n",
    "        stream = MyStreamer(APP_KEY, APP_SECRET,OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "        print('Connecting to twitter: will take a minute')\n",
    "    except ValueError:\n",
    "        print('OOPS! that hurts, something went wrong while making connection with Twitter: '+str(ValueError))\n",
    "    #global target\n",
    "    \n",
    "    # Filter based on bounding box and word filter that you want to search on twitter see twitter api documentation for more info\n",
    "    try:\n",
    "        stream.statuses.filter(locations='LONGITUDEmin,LATITUDEmin,LONGITUDEmax,LATITUDEmax',track='HASHTAG/KEYWORDS')     \n",
    "    except ValueError:\n",
    "        print('OOPS! that hurts, something went wrong while getting the stream from Twitter: '+str(ValueError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this function to start the Twitter Streaming              \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    write_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./output/twitter_data/Geotaggedtweets_22to23june2019.csv',encoding='iso-8859-1')\n",
    "\n",
    "#create geopandas geodataframe\n",
    "geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "df = df.drop(['latitude', 'longitude'], axis=1)\n",
    "gdf = GeoDataFrame(df, crs={'init': 'epsg:4326'}, geometry=geometry)\n",
    "gdf.to_file(\"./output/twitter_data/Geotaggedtweets_22to23june2019.geojson\",driver=\"GeoJSON\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
